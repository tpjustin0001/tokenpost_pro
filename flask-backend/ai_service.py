
import os
import json
from datetime import datetime
from openai import OpenAI


class AIService:
    def __init__(self):
        self.xai_key = os.environ.get("XAI_API_KEY")
        self.openai_key = os.environ.get("OPENAI_API_KEY")
        
        self.client_gpt = None
        self.client_grok = None
        
        # 1. Init OpenAI (Main Processor)
        if self.openai_key:
            self.client_gpt = OpenAI(api_key=self.openai_key)
        
        # 2. Init xAI (Sentiment Engine)
        if self.xai_key:
            self.client_grok = OpenAI(
                api_key=self.xai_key,
                base_url="https://api.x.ai/v1"
            )

        # In-memory Cache
        self._cache = {}
        self.CACHE_TTL_GLOBAL = 3600
        self.CACHE_TTL_ASSET = 900

    def _get_grok_sentiment(self, news_list):
        """
        Use Grok (xAI) to extract deep social sentiment from news.
        """
        if not self.client_grok or not news_list:
            if not self.client_grok:
                print("‚ö†Ô∏è xAI Client not initialized (Missing XAI_API_KEY)")
            return "Grok AI: No sentiment data available."

        news_text = "\n".join([f"- {item['title']} ({item['source']})" for item in news_list])
        
        try:
            # Using 'grok-beta' (or 'grok-2-latest' if beta is deprecated)
            response = self.client_grok.chat.completions.create(
                model="grok-beta", 
                messages=[
                    {"role": "system", "content": "You are Grok, a real-time Social Sentiment Engine. Analyze the crypto news headlines. Output a brief, witty, uncensored, and slightly edgy paragraph about the current market 'vibe' and crowd psychology. Be bold. Output in KOREAN."},
                    {"role": "user", "content": f"Headlines:\n{news_text}"}
                ],
                temperature=0.9
            )
            return response.choices[0].message.content
        except Exception as e:
            print(f"‚ùå Grok Sentiment Failed: {e}")
            # Fallback to OpenAI if Grok fails key/quota
            return self._get_openai_sentiment_fallback(news_list)

    def _get_openai_sentiment_fallback(self, news_list):
        """Fallback to OpenAI if Grok fails"""
        try:
            print("üîÑ Falling back to OpenAI for sentiment...")
            news_text = "\n".join([f"- {item['title']} ({item['source']})" for item in news_list])
            response = self.client_gpt.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are a crypto sentiment analyzer. Output a witty, edgy paragraph about market vibe in Korean."},
                    {"role": "user", "content": f"Headlines:\n{news_text}"}
                ],
                temperature=0.8
            )
            return response.choices[0].message.content
        except Exception as e:
            return "Data analysis failed."

    def analyze_global_market(self, market_data, news_list=[]):
        cache_key = 'GLOBAL_MARKET_V3'
        cached = self._get_cached_data(cache_key, self.CACHE_TTL_GLOBAL)
        if cached: return cached

        if not self.client_gpt:
            return self._get_mock_global_analysis()

        # Step 1: Get Grok Sentiment
        grok_sentiment = self._get_grok_sentiment(news_list)

        # Step 2: GPT Main Analysis (acting as parsing layer or using Grok directly if possible)
        # Note: We are using GPT-4o-mini to structure the data, but we inject Grok's sentiment.
        # Ideally, we would use Grok for the whole thing if it supported JSON mode reliably.
        
        system_prompt = f"""
        You are a 'Crypto Social Pulse' Analyzer.
        
        INPUT CONTEXT:
        1. Market Data (Technical/Macro)
        2. Social Sentiment (AI Analysis): "{grok_sentiment}"
        
        TASK:
        Generate a "Social Pulse" report in STRICT JSON format.
        The content must be in KOREAN (except for usernames/handles and numbers).
        
        JSON Structure:
        {{
            "grok_saying": "A witty, edgy, and insightful one-liner about the market vibe. Be cynical but accurate. IN KOREAN.",
            "atmosphere_score": int(0-100), // 0=Extreme Fear, 100=Extreme Greed
            "atmosphere_label": "Í≥µÌè¨ (Fear) | Ï§ëÎ¶Ω (Neutral) | ÌÉêÏöï (Greed)",
            "market_keywords": ["#Keyword1", "#Keyword2", "#Keyword3"],
            "top_tweets": [
                {{ "author": "User Name", "handle": "@handle", "content": "Tweet text...", "time": "2m ago" }},
                {{ "author": "Analyst", "handle": "@analyst", "content": "Analysis...", "time": "15m ago" }},
                {{ "author": "News", "handle": "@news", "content": "Breaking...", "time": "1h ago" }}
            ],
            "whale_alerts": [
                {{ "symbol": "BTC", "type": "Îß§Ïàò", "amount": "$120M", "time": "5Î∂Ñ Ï†Ñ", "note": "Î∞îÏù¥ÎÇ∏Ïä§ ÏûÖÍ∏à" }},
                {{ "symbol": "ETH", "type": "Îß§ÎèÑ", "amount": "$80M", "time": "12Î∂Ñ Ï†Ñ", "note": "Í±∞ÎûòÏÜå Ï∂úÍ∏à" }}
            ],
            "sectorAnalysis": [ {{ "name": "...", "signal": "...", "score": int, "insight": "..." }} ],
            "radar_data": [
                 {{ "label": "Macro", "value": int }},
                 {{ "label": "Technical", "value": int }},
                 {{ "label": "On-Chain", "value": int }},
                 {{ "label": "Sentiment", "value": int }},
                 {{ "label": "Innovation", "value": int }}
            ]
        }}
        """

        try:
            response = self.client_gpt.chat.completions.create(
                model="gpt-4o-mini",
                response_format={"type": "json_object"},
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"Market Data: {str(market_data)}"}
                ]
            )
            
            result_json = response.choices[0].message.content
            parsed_result = json.loads(result_json)
            parsed_result['timestamp'] = datetime.now().isoformat()
            parsed_result['recent_news'] = news_list
            parsed_result['grok_sentiment_raw'] = grok_sentiment # Store raw Grok output if needed
            
            self._set_cache_data(cache_key, parsed_result)
            return parsed_result

        except Exception as e:
            print(f"Hybrid Analysis Failed: {e}")
            return self._get_mock_global_analysis()

    def analyze_asset(self, symbol, asset_data_summary, news_list=[]):
        cache_key = f'ASSET_{symbol}'
        cached = self._get_cached_data(cache_key, self.CACHE_TTL_ASSET)
        if cached: return cached

        if not self.client_gpt:
            return self._get_mock_asset_analysis(symbol)

        # Step 1: Grok Sentiment
        grok_sentiment = self._get_grok_sentiment(news_list)

        # Step 2: GPT Analysis
        system_prompt = f"""
        Analyze {symbol}.
        
        Social Sentiment (Grok): "{grok_sentiment}"
        
        Return STRICT KOREAN JSON.
        
        JSON Structure:
        {{
            "assetName": "{symbol}",
            "category": "...",
            "overallScore": float(0-10),
            "summary": "...",
            "detailed_analysis": {{ "market_context": "...", "technical_outlook": "...", "on_chain_verdict": "..." }},
            "radarData": [ {{ "label": "ÌéÄÎçîÎ©òÌÉà", "value": int }} ... ],
            "metrics": [], "risks": [], "opportunities": [], "recommendation": "..."
        }}
        """

        try:
            response = self.client_gpt.chat.completions.create(
                model="gpt-4o-mini", # Use GPT for structure
                response_format={"type": "json_object"},
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"Data: {str(asset_data_summary)}"}
                ]
            )
            
            result_json = response.choices[0].message.content
            parsed_result = json.loads(result_json)
            parsed_result['timestamp'] = datetime.now().isoformat()
            parsed_result['recent_news'] = news_list
            
            self._set_cache_data(cache_key, parsed_result)
            return parsed_result
        except Exception as e:
            print(f"Asset Analysis Failed: {e}")
            return self._get_mock_asset_analysis(symbol)

    def _get_cached_data(self, key, ttl):
        if key in self._cache:
            entry = self._cache[key]
            age = (datetime.now() - entry['time']).total_seconds()
            if age < ttl:
                return entry['data']
        return None

    def _set_cache_data(self, key, data):
        self._cache[key] = {
            'data': data,
            'time': datetime.now()
        }

    def _get_mock_global_analysis(self):
        return {
            "overallScore": 65,
            "marketPhase": "Accumulation",
            "summary": "AI ÏÑúÎπÑÏä§ Ïó∞Í≤∞Ïù¥ ÏõêÌôúÌïòÏßÄ ÏïäÏäµÎãàÎã§. Í∏∞Î≥∏ Îç∞Ïù¥ÌÑ∞Îßå Ï†úÍ≥µÎê©ÎãàÎã§. ÌòÑÏû¨ ÏãúÏû•ÏùÄ Ï£ºÏöî ÏßÄÏßÄÏÑ† ÏúÑÏóêÏÑú Ìö°Î≥¥ÌïòÎ©∞ Îã§Ïùå Î∞©Ìñ•ÏÑ±ÏùÑ Î™®ÏÉâÌïòÍ≥† ÏûàÏäµÎãàÎã§.",
            "macro_factors": [
                {"name": "Interest Rates", "impact": "Neutral", "detail": "Í∏àÎ¶¨ Ï†ïÏ±Ö Î∂àÌôïÏã§ÏÑ± ÏßÄÏÜç"},
                {"name": "Inflation", "impact": "Negative", "detail": "CPI Îç∞Ïù¥ÌÑ∞ Ï£ºÏãú ÌïÑÏöî"}
            ],
            "radar_data": [
                {"label": "Macro", "value": 60},
                {"label": "Technical", "value": 70},
                {"label": "On-Chain", "value": 65},
                {"label": "Sentiment", "value": 50},
                {"label": "Innovation", "value": 80}
            ],
            "sectorAnalysis": [
                {"name": "DeFi", "signal": "Accumulate", "score": 75, "insight": "TVL ÏÉÅÏäπ Ï∂îÏÑ∏ Ïú†ÏßÄ"},
                {"name": "GameFi", "signal": "Watch", "score": 60, "insight": "Ïã†Í∑ú Ïú†Ï†Ä Ïú†ÏûÖ Ï†ïÏ≤¥"}
            ],
            "onchain_signals": [
                {"metric": "Exchange Inflow", "signal": "Bullish", "value": "Low", "comment": "Îß§ÎèÑ ÏïïÎ†• Í∞êÏÜå"}
            ],
            "risks": ["Í∑úÏ†ú Î∂àÌôïÏã§ÏÑ±", "Í±∞ÏãúÍ≤ΩÏ†ú ÏúÑÏ∂ï"],
            "opportunities": ["ÎπÑÌä∏ÏΩîÏù∏ Î∞òÍ∞êÍ∏∞", "Ïù¥ÎçîÎ¶¨ÏõÄ ÏóÖÍ∑∏Î†àÏù¥Îìú"],
            "recommendation": "DCA (Î∂ÑÌï† Îß§Ïàò) Ï†ÑÎûµ Ïú†ÏßÄ",
            "actionable_insight_summary": "Îã®Í∏∞ Î≥ÄÎèôÏÑ±Ïóê Ï£ºÏùòÌïòÎêò Ï§ëÏû•Í∏∞Ï†Å Í¥ÄÏ†êÏùò Îß§Ïßë Ïú†Ìö®",
            "timestamp": datetime.now().isoformat(),
            "recent_news": [],
            
            # OpenAI/Grok Fallback Fields
            "grok_saying": "AI Ïó∞Í≤∞Ïù¥ ÏßÄÏó∞ÎêòÍ≥† ÏûàÏäµÎãàÎã§. Ïû†Ïãú ÌõÑ Îã§Ïãú ÌôïÏù∏Ìï¥Ï£ºÏÑ∏Ïöî.",
            "atmosphere_score": 50,
            "atmosphere_label": "Ï§ëÎ¶Ω (Neutral)",
            "market_keywords": ["#Bitcoin", "#Crypto", "#HODL"],
            "top_tweets": [],
            "whale_alerts": []
        }

    def _get_mock_asset_analysis(self, symbol, error_msg=None):
        return {
            "assetName": symbol,
            "category": "Crypto",
            "overallScore": 5.0,
            "summary": error_msg or "AI Î∂ÑÏÑùÏùÑ ÏÇ¨Ïö©Ìï† Ïàò ÏóÜÏäµÎãàÎã§. Ïû†Ïãú ÌõÑ Îã§Ïãú ÏãúÎèÑÌï¥Ï£ºÏÑ∏Ïöî.",
            "detailed_analysis": {
                "market_context": "Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°±",
                "technical_outlook": "Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°±",
                "on_chain_verdict": "Îç∞Ïù¥ÌÑ∞ Î∂ÄÏ°±"
            },
            "radarData": [
                {"label": "ÌéÄÎçîÎ©òÌÉà", "value": 50},
                {"label": "Î™®Î©òÌÖÄ", "value": 50},
                {"label": "Í∏∞Ïà†Ï†ÅÎ∂ÑÏÑù", "value": 50},
                {"label": "Í≤ÄÏÉâÎüâ", "value": 50},
                {"label": "ÌòÅÏã†ÏÑ±", "value": 50}
            ],
            "metrics": [],
            "risks": [],
            "opportunities": [],
            "recommendation": "Hold",
            "timestamp": datetime.now().isoformat()
        }

# Singleton instance
ai_service = AIService()
